from matplotlib import _preprocess_data
import numpy as np
import streamlit as st
from streamlit_option_menu import option_menu
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestRegressor
from sklearn.cluster import KMeans


# Function to load data (replace with your actual data loading code)
@st.cache_data

def load_data():
    data = pd.read_csv('/Users/venkat/Documents/Final project/classification_data.csv')  # Update this line with your dataset
    return data

# Function to create a distribution plot
def plot_distribution(data, column, title):
    st.set_option('deprecation.showPyplotGlobalUse', False)
    plt.figure(figsize=(10, 6))
    sns.histplot(data[column], kde=True)
    plt.title(title)
    plt.xlabel(column)
    plt.ylabel('Frequency')
    st.pyplot()

def train_model(X_train, y_train):
    # Create a machine learning model (for example, a random forest classifier)
    model = RandomForestClassifier()

    # Train the model using the training data
    model.fit(X_train, y_train)
    
    return model
# Streamlit application layout
st.title('Final Project Presentation')

# Creating a sidebar for navigation
with st.sidebar:
    selected = option_menu("Main Menu", ["Home", "EDA", "Model Building", "Final Output"],
                           icons=['house', 'bar-chart-line', 'wrench', 'file-text'], default_index=0)

# Home page
if selected == "Home":
    st.subheader("About the Dataset")
    data = load_data()  # Load your data

    # Display basic information about the dataset
    if st.checkbox('Show Dataset'):
        st.dataframe(data)

    st.write('Data Dimensions:', data.shape)
    st.write('Column Names:', data.columns.tolist())
    st.write('Data Types:', data.dtypes)

    if st.checkbox('Show Summary'):
        st.dataframe(data.describe())
        
    sns.set(style="whitegrid")
    st.set_option('deprecation.showPyplotGlobalUse', False)
# Plotting the distribution of the target variable
    plt.figure(figsize=(6,4))
    sns.countplot(x='has_converted', data=data)
    plt.title('Distribution of Target Variable (has_converted)')
    plt.xlabel('Has Converted')
    plt.ylabel('Count')
    st.pyplot()
    
   
# EDA page
elif selected == "EDA":
    st.subheader("Exploratory Data Analysis")
    data = load_data()  # Load your data

    # Ensure the columns exist in your dataset
    if all(col in data.columns for col in ['count_session', 'count_hit', 'transactionRevenue']):
        plot_distribution(data, 'count_session', 'Distribution of Session Counts')
        plot_distribution(data, 'count_hit', 'Distribution of Hit Counts')
        plot_distribution(data, 'transactionRevenue', 'Distribution of Transaction Revenue')
    else:
        st.error("Required columns are not in the dataset")
    # Selecting numeric columns for the correlation matrix
    numeric_data = data.select_dtypes(include=['int64', 'float64'])

# Plotting the correlation matrix
    plt.figure(figsize=(10, 10))
    sns.heatmap(numeric_data.corr(), annot=True, fmt=".1f", cmap='coolwarm')
    plt.title('Correlation Matrix')
    st.pyplot()  
    
    st.subheader('Numerical Data Distribution')
    numerical_columns = data.select_dtypes(include=['int64', 'float64']).columns
    for col in numerical_columns:
        st.subheader(f'Histogram for {col}')
        fig, ax = plt.subplots()
        sns.histplot(data[col], ax=ax)
        st.pyplot(fig)
    st.subheader('Target Variable Distribution')
    fig, ax = plt.subplots(figsize=(8, 8))  # Adjust the size as needed
    data['has_converted'].value_counts().plot(kind='pie', autopct='%1.1f%%', ax=ax)
    st.pyplot(fig)

elif selected == "Final Output":
    st.subheader("Final Output")
    data = load_data()
    df= data
    def display_data(df):
            # Calculate total click and session counts
            total_clicks = df['count_hit'].sum()
            total_sessions = df['count_session'].sum()

            # Calculate device category breakdown
            device_counts = df['device_deviceCategory'].value_counts()

            # Calculate conversion counts
            conversions = df['has_converted'].value_counts()

            return total_clicks, total_sessions, device_counts, conversions

        # Streamlit app layout
    st.title('Data Analysis App')

            # Load data
    data = load_data()

        # Button to update counts
    if st.button('Update Counts'):
                total_clicks, total_sessions, device_counts, conversions = display_data(data)

                # Display results
                st.write(f'Total Click Count: {total_clicks}')
                st.write(f'Total Session Count: {total_sessions}')
                st.write('Device Category Breakdown:')
                st.write(device_counts)
                st.write('Conversion Counts:')
                st.write(f'Converted: {conversions.get(1, 0)}')
                st.write(f'Not Converted: {conversions.get(0, 0)}')
    
        
elif selected == "Model Building":
    st.subheader("Model Building")
    data = load_data()
     
    data = data[['count_session', 'count_hit', 'channelGrouping', 'device_browser', 'geoNetwork_region', 'has_converted', 'transactionRevenue']].dropna()

# Encoding categorical variables and scaling numerical features
    categorical_features = ['channelGrouping', 'device_browser', 'geoNetwork_region']
    numerical_features = ['count_session', 'count_hit']

    categorical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
        ('onehot', OneHotEncoder(handle_unknown='ignore'))])

    numerical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='mean')),
        ('scaler', StandardScaler())])

    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numerical_transformer, numerical_features),
            ('cat', categorical_transformer, categorical_features)])

    # Define target for regression and classification
    y_reg = data['transactionRevenue']  # Target for regression
    y_cls = data['has_converted']       # Target for classification
    X = data.drop(['has_converted', 'transactionRevenue'], axis=1)
    


    # Splitting the data into training and test sets
    X_train, X_test, y_train_reg, y_test_reg = train_test_split(X, y_reg, test_size=0.2, random_state=42)
    _, _, y_train_cls, y_test_cls = train_test_split(X, y_cls, test_size=0.2, random_state=42)

    


    
    # Model building

    # 1. Regression Model (Random Forest Regressor)
    regressor = Pipeline(steps=[('preprocessor', preprocessor),
                                ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))])

    # 2. Classification Model (Random Forest Classifier)
    classifier = Pipeline(steps=[('preprocessor', preprocessor),
                                ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))])

    # 3. Clustering Model (KMeans)
    # For clustering, we need to preprocess the entire dataset as there's no y target
    X_preprocessed = preprocessor.fit_transform(X)
    kmeans = KMeans(n_clusters=3, random_state=42)

    # Fit the models
    regressor.fit(X_train, y_train_reg)
    classifier.fit(X_train, y_train_cls)
    kmeans.fit(X_preprocessed)

    # Predictions for evaluation
    y_pred_reg = regressor.predict(X_test)
    y_pred_cls = classifier.predict(X_test)

    # For clustering, assign each sample to a cluster
    clusters = kmeans.predict(X_preprocessed)

    # Prepare results for plotting
    results = {
        "Regression Model Predictions": y_pred_reg,
        "Classification Model Predictions": y_pred_cls,
        "Clustering Model Assignments": clusters
    }

    results
    
    def create_plots(y_test_reg, y_pred_reg, y_test_cls, y_pred_cls, clusters):
        plt.figure(figsize=(18, 6))
        
        # Regression Plot
        plt.subplot(1, 3, 1)
        sns.scatterplot(x=y_test_reg, y=y_pred_reg)
        plt.title('Regression Model: Actual vs Predicted Revenue')
        plt.xlabel('Actual Revenue')
        plt.ylabel('Predicted Revenue')

        # Classification Plot
        plt.subplot(1, 3, 2)
        sns.scatterplot(x=y_test_cls, y=y_pred_cls)
        plt.title('Classification Model: Actual vs Predicted Conversion')
        plt.xlabel('Actual Conversion (0=No, 1=Yes)')
        plt.ylabel('Predicted Conversion Probability')

        # Clustering Plot
        plt.subplot(1, 3, 3)
        sns.histplot(clusters, kde=False, bins=3)
        plt.title('Clustering Model: Visitor Segments')
        plt.xlabel('Cluster')
        plt.ylabel('Number of Visitors')

        return plt

    # Streamlit app
        st.title("Model Visualization")

    # Generate plots
    fig = create_plots(y_test_reg, y_pred_reg, y_test_cls, y_pred_cls, clusters)

    # Display plots in Streamlit
    st.pyplot(fig)

    def preprocess_data(data):
        # Example preprocessing
        # For numerical columns: fill missing values with the mean
        for col in data.select_dtypes(include='number').columns:
            data[col].fillna(data[col].mean(), inplace=True)

        # For categorical columns: fill missing values with the mode (most frequent value)
        for col in data.select_dtypes(include='object').columns:
            data[col].fillna(data[col].mode()[0], inplace=True)

        return data

# Assuming 'data' is your pandas DataFrame
    data = preprocess_data(data)

        
    regression_predictions = np.array([29676397., 0., 87967380., 28656201., 57425197., 0.])
    classification_predictions = np.array([1, 0, 1, 1, 0, 0])
    clustering_assignments = np.array([0, 0, 0, 2, 2, 2])

    # Streamlit application
    st.title("Model Predictions Visualization")

    # Regression Model Predictions
    st.subheader("Regression Model Predictions")
    st.write(pd.DataFrame(regression_predictions, columns=['Predicted Value']))

    # Plot for Regression Predictions
    plt.figure(figsize=(10, 4))
    sns.histplot(regression_predictions, kde=True)
    plt.title('Distribution of Regression Predictions')
    st.pyplot(plt)

    # Classification Model Predictions
    st.subheader("Classification Model Predictions")
    st.write(pd.DataFrame(classification_predictions, columns=['Predicted Class']))

    # Plot for Classification Predictions
    plt.figure(figsize=(10, 4))
    sns.countplot(x=classification_predictions)
    plt.title('Count of Classification Predictions')
    st.pyplot(plt)

    # Clustering Model Assignments
    st.subheader("Clustering Model Assignments")
    st.write(pd.DataFrame(clustering_assignments, columns=['Cluster Assignment']))

    # Plot for Clustering Assignments
    plt.figure(figsize=(10, 4))
    sns.countplot(x=clustering_assignments)
    plt.title('Count of Clustering Assignments')
    st.pyplot(plt)
